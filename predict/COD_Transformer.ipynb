{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import warnings\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.layers import Dropout, Dense, LSTM,Activation,GRU,SimpleRNN\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_init = pd.read_excel(\"shujuji.xlsx\")\n",
    "x,y = data_init.iloc[:,1:6],data_init.iloc[:,-1]\n",
    "data_init.iloc[:,1:].agg(['min','max', \"mean\"])\n",
    "data_init.iloc[:,1:-1]\n",
    "\n",
    "scaler_input = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaler_output = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "data_input = data_init.iloc[:,1:-1]\n",
    "data_output = np.array(data_init.iloc[:,-1]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "x_data = scaler_input.fit_transform(data_input)\n",
    "y_data = scaler_output.fit_transform(data_output)\n",
    "\n",
    "time_steps = 2\n",
    "\n",
    "xx_data = []\n",
    "yy_data = []\n",
    "\n",
    "for i in range(time_steps, len(x_data)):\n",
    "    xx_data.append(x_data[i - time_steps:i, :].tolist())\n",
    "    yy_data.append(y_data[i])\n",
    "    \n",
    "yy_data = np.array(yy_data)\n",
    "\n",
    "np.array(xx_data).shape,np.array(yy_data).shape\n",
    "\n",
    "train_X_nn, train_y_nn = np.array(xx_data)[:184,:], yy_data[:184]\n",
    "test_X_nn, test_y_nn = np.array(xx_data)[184:,:], yy_data[184:]\n",
    "\n",
    "x_train,y_train = np.array(train_X_nn),np.array(train_y_nn)\n",
    "\n",
    "x_test,y_test = np.array(test_X_nn),np.array(test_y_nn)\n",
    "\n",
    "\n",
    "def show_data(test_y,predict_y,title):\n",
    "    plt.figure(figsize=(10,8),dpi=100)\n",
    "    x = [i for i in range(test_y.shape[0])]\n",
    "    plt.plot(x, test_y, color='navy',lw = 2, label='Actual data')\n",
    "    plt.plot(x, predict_y, color='c',lw = 2, label='Predict data')\n",
    "    x_label = [i for i in x[::5]]\n",
    "    \n",
    "    y_label = [j for j in range(0,500,50)]\n",
    "    plt.yticks(y_label)\n",
    "    plt.xticks(x_label)\n",
    "    plt.xlabel('Time/d')\n",
    "    plt.ylabel('COD')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import math as mt\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \n",
    "        super(PositionalEncoding, self).__init__()      \n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-mt.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "          \n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=2, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(2*feature_size,1)\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.feature_size = feature_size\n",
    "        self.num_layers   = num_layers\n",
    "        self.dropout      = dropout\n",
    "        \n",
    "    def feature(self):\n",
    "        return{\"feature_size\":self.feature_size,\"num_layers\":self.num_layers,\"dropout\":self.dropout}\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self,src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,self.src_mask)\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "class General_Regression_Training_3d():\n",
    "\n",
    "    def fitness(self, evaluationStr=\"r2\"):\n",
    "        if (evaluationStr == \"r2\"):\n",
    "            return self.r2\n",
    "        elif (evaluationStr == \"r2_adjusted\"):\n",
    "            return self.r2_adjusted\n",
    "        elif (evaluationStr == \"rmsle\"):\n",
    "            return self.rmsle\n",
    "        elif (evaluationStr == \"mape\"):\n",
    "            return self.mape\n",
    "        elif (evaluationStr == \"r2_adjusted\"):\n",
    "            return self.r2_adjusted\n",
    "        elif (evaluationStr == \"mad\"):\n",
    "            return self.mad\n",
    "        elif (evaluationStr == \"mae\"):\n",
    "            return self.mae\n",
    "        \n",
    "    def save_results(self):\n",
    "        resultTitle     = [str(line) for line in self.resultDict.keys()]\n",
    "        resultList      = [ \"_\".join([ str(l) for l in line]) if isinstance(line,list) else str(line) for line in self.resultDict.values()]\n",
    "        y_test          = self.y_test\n",
    "        test_prediction = self.test_prediction\n",
    "        save_path       = self.save_path\n",
    "\n",
    "        save_result = \"/\".join([save_path, 'result.csv'])\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        try:\n",
    "            count = len(open(save_result, 'rU').readlines())\n",
    "        except:\n",
    "            count = 1\n",
    "\n",
    "        resultTitle.insert(0, \"count\")\n",
    "        resultList.insert(0, str(count))\n",
    "        \n",
    "        if not os.path.exists(save_result):\n",
    "            with open(save_result, 'w') as f:\n",
    "                titleStr = \",\".join(resultTitle)\n",
    "                f.write(titleStr)\n",
    "                f.write('\\n')\n",
    "        \n",
    "        with open(save_result, 'a+') as f:\n",
    "            contentStr = \",\".join(resultList)\n",
    "            f.write(contentStr)\n",
    "            f.write('\\n')\n",
    "        Loss_path = os.path.join(save_path, 'Loss')\n",
    "        if not os.path.exists(Loss_path):\n",
    "            os.makedirs(Loss_path)\n",
    "        \n",
    "        save_Loss = os.path.join(Loss_path, str(count) + '.csv')\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df[\"TrainLoss\"] = self.TrainLosses\n",
    "        df[\"TestLoss\"] = self.TestLosses\n",
    "        df.to_csv(save_Loss, index=False)\n",
    "        pred_path = os.path.join(save_path, 'Prediction')\n",
    "        if not os.path.exists(pred_path):\n",
    "            os.makedirs(pred_path)\n",
    "\n",
    "        save_prediction = os.path.join(pred_path, str(count) + '.csv')\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        df[\"y_test\"] = [i for i in y_test]\n",
    "        df[\"test_prediction\"] =[i for i in test_prediction]\n",
    "        df.to_csv(save_prediction, index=False)\n",
    "\n",
    "        print('Save the value of prediction successfully!!')\n",
    "\n",
    "        model_path = os.path.join(save_path, 'Model')\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "\n",
    "        if(self.use_more_gpu):\n",
    "            torch.save(self.net.state_dict(), os.path.join(model_path, str(count) + \".pth\"))\n",
    "        else:\n",
    "            torch.save(self.net.state_dict(), os.path.join(model_path, str(count) + \".pth\"))\n",
    "\n",
    "        return count\n",
    "\n",
    "\n",
    "    def reg_calculate(self,true, prediction, features=None):\n",
    "        '''\n",
    "            To calculate the result of regression,\n",
    "            including mse, rmse, mae, r2, four criterions.\n",
    "        '''\n",
    "        prediction[prediction < 0] = 0\n",
    "\n",
    "        mse = metrics.mean_squared_error(true, prediction)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        mae = metrics.mean_absolute_error(true, prediction)\n",
    "        mape = np.mean(np.abs((true - prediction) / true)) * 100\n",
    "\n",
    "        r2 = metrics.r2_score(true, prediction)\n",
    "        rmsle = np.sqrt(metrics.mean_squared_log_error(true, prediction))\n",
    "\n",
    "        try:\n",
    "            n = len(true)\n",
    "            p = features\n",
    "            r2_adjusted = 1-((1-metrics.r2_score(true, prediction))*(n-1))/(n-p-1)\n",
    "        except:\n",
    "            print('if you wanna get the value of r2_adjusted, you can define the number of features, '\n",
    "                  'which is the third parameter.')\n",
    "            return mse, rmse, mae, mape, r2, rmsle\n",
    "\n",
    "        return mse, rmse, mae, mape, r2, r2_adjusted, rmsle\n",
    "\n",
    "\n",
    "    def __init__(self,net,learning_rate = [1e-3,1e-5,1e-7], batch_size = 1024, epoch = 2000, use_more_gpu = False,weight_decay=1e-8, device=0 ,save_path='CNN_Result'):\n",
    "\n",
    "        self.net = net\n",
    "        self.resultDict = {\"learning_rate\":learning_rate,\"batch_size\":batch_size,\"epoch\":epoch,\"weight_decay\":weight_decay,\"use_more_gpu\":use_more_gpu,\"device\":device,}\n",
    "        self.resultDict = dict(self.resultDict,**self.net.feature())\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.use_more_gpu = use_more_gpu\n",
    "        self.lr = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.weight_decay = weight_decay\n",
    "        self.device = device\n",
    "        self.epoch = epoch\n",
    "        \n",
    "        self.save_path = save_path\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "\n",
    "        self.avgLossList = []\n",
    "        self.TrainLosses = []\n",
    "        self.TestLosses = []\n",
    "        self.t = 0\n",
    "        self.D = []\n",
    "        self.n = 0\n",
    "        self.limit = [1e-5, 1e-6, 1e-7]\n",
    "        \n",
    "    def create_batch_size(self, X_train, y_train):\n",
    "        p = np.random.permutation(X_train.shape[0])\n",
    "        data = X_train[p]\n",
    "        label = y_train[p]\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "        batch_len = X_train.shape[0] // batch_size + 1\n",
    "\n",
    "        b_datas = []\n",
    "        b_labels = []\n",
    "        for i in range(batch_len):\n",
    "            try:\n",
    "                batch_data = data[batch_size * i: batch_size * (i + 1)]\n",
    "                batch_label = label[batch_size * i: batch_size * (i + 1)]\n",
    "            except:\n",
    "                batch_data = data[batch_size * i: -1]\n",
    "                batch_label = label[batch_size * i: -1]\n",
    "            b_datas.append(batch_data)\n",
    "            b_labels.append(batch_label)\n",
    "\n",
    "        return b_datas, b_labels\n",
    "    \n",
    "    \n",
    "        \n",
    "    # 訓練函數\n",
    "    def fit(self, X_train, y_train, X_test, y_test):\n",
    "        ''' training the network '''\n",
    "        if y_train.ndim == 1:\n",
    "            y_train = y_train.reshape(-1, 1)\n",
    "        \n",
    "        if y_test.ndim == 1:\n",
    "            y_test = y_test.reshape(-1, 1)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "\n",
    "        b_data, b_labels = self.create_batch_size(X_train, y_train)\n",
    "        \n",
    "        save_result = os.path.join(self.save_path, 'Results.csv')\n",
    "        try:\n",
    "            count = len(open(save_result, 'rU').readlines())\n",
    "        except:\n",
    "            count = 1\n",
    "\n",
    "        net_weight = os.path.join(self.save_path, 'Weight')\n",
    "        if not os.path.exists(net_weight):\n",
    "            os.makedirs(net_weight)\n",
    "        \n",
    "        net_path = os.path.join(net_weight, str(count) + '.pkl')\n",
    "        net_para_path = os.path.join(net_weight, str(count) + '_parameters.pkl')\n",
    "        \n",
    "        \n",
    "        device = torch.device(self.device if torch.cuda.is_available() else \"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"Let's use GPU: {}\".format(self.device))\n",
    "        else:\n",
    "            print(\"Let's use CPU\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        if self.use_more_gpu and torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs\")\n",
    "            self.net = nn.DataParallel(self.net)\n",
    "        self.net.to(device)\n",
    "        \n",
    "        self.net.train()\n",
    "        try:\n",
    "            optim = torch.optim.Adam(self.net.parameters(), lr=self.lr[0], weight_decay=self.weight_decay)\n",
    "        except:\n",
    "            optim = torch.optim.Adam(self.net.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        print(\"\")\n",
    "\n",
    "        start = time.time()\n",
    "        limit = self.limit[0]\n",
    "        for e in range(self.epoch):\n",
    "            \n",
    "            tempLoss = []\n",
    "            # 訓練模式\n",
    "            self.net.train()\n",
    "            for i in range(len(b_data)):\n",
    "                if torch.cuda.is_available():\n",
    "                    train_x = Variable(torch.FloatTensor(b_data[i])).to(device)\n",
    "                    train_y = Variable(torch.FloatTensor(b_labels[i])).to(device)\n",
    "                else:\n",
    "                    train_x = Variable(torch.FloatTensor(b_data[i]))\n",
    "                    train_y = Variable(torch.FloatTensor(b_labels[i]))\n",
    "\n",
    "\n",
    "                prediction = self.net(train_x)\n",
    "                \n",
    "                loss = criterion(prediction, train_y)\n",
    "                tempLoss.append(float(loss))\n",
    "                \n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "            self.D.append(loss.cpu().data.numpy())\n",
    "            avgloss =  np.array(tempLoss).sum() / len(tempLoss)\n",
    "            self.avgLossList.append(avgloss)\n",
    "            \n",
    "            \n",
    "            if( ( e + 1 ) % 100 == 0):\n",
    "                print('Training... epoch: {}, loss: {}'.format((e + 1), self.avgLossList[-1]))\n",
    "\n",
    "                self.net.eval()\n",
    "                if torch.cuda.is_available():\n",
    "                    test_x = Variable(torch.FloatTensor(self.X_test)).to(device)\n",
    "                    test_y = Variable(torch.FloatTensor(self.y_test)).to(device)\n",
    "                else:\n",
    "                    test_x = Variable(torch.FloatTensor(self.X_test))\n",
    "                    test_y = Variable(torch.FloatTensor(self.y_test))\n",
    "\n",
    "                test_prediction = self.net(test_x)\n",
    "                test_loss = criterion(test_prediction, test_y)\n",
    "\n",
    "                self.TrainLosses.append(avgloss)\n",
    "                self.TestLosses.append(test_loss.cpu().data.numpy())\n",
    "\n",
    "                self.test_prediction = test_prediction.cpu().data.numpy()\n",
    "                self.test_prediction[self.test_prediction < 0] = 0\n",
    "                \n",
    "                \n",
    "            \n",
    "            if len(self.D) >= 20:\n",
    "                loss1 = np.mean(np.array(self.D[-20:-10]))\n",
    "                loss2 = np.mean(np.array(self.D[-10:]))\n",
    "                d = float(np.abs(loss2 - loss1))\n",
    "\n",
    "                \n",
    "                if d < limit or e == self.epoch-1  or e > (self.epoch-1)/3 * (self.n + 1): \n",
    "                    self.D = []\n",
    "                    self.n += 1\n",
    "                    print('The error changes within {}'.format(limit))\n",
    "                    self.e = e + 1\n",
    "                    print(\n",
    "                        'Training... epoch: {}, loss: {}'.format((e + 1), loss.cpu().data.numpy()))\n",
    "                    \n",
    "                    \n",
    "                    torch.save(self.net, net_path)\n",
    "                    torch.save(self.net.state_dict(), net_para_path)\n",
    "                    \n",
    "                    self.net.eval()\n",
    "                    if torch.cuda.is_available():\n",
    "                        test_x = Variable(torch.FloatTensor(self.X_test)).to(device)\n",
    "                        test_y = Variable(torch.FloatTensor(self.y_test)).to(device)\n",
    "                    else:\n",
    "                        test_x = Variable(torch.FloatTensor(self.X_test))\n",
    "                        test_y = Variable(torch.FloatTensor(self.y_test))\n",
    "                    \n",
    "                    test_prediction = self.net(test_x)\n",
    "                    test_loss = criterion(test_prediction, test_y)\n",
    "\n",
    "                \n",
    "                    self.test_prediction = test_prediction.cpu().data.numpy()\n",
    "                    self.test_prediction[self.test_prediction < 0] = 0\n",
    "                    \n",
    "                    \n",
    "                    self.mse, self.rmse, self.mae, self.mape, \\\n",
    "                        self.r2, self.r2_adjusted, self.rmsle = self.reg_calculate(self.y_test, self.test_prediction  ,self.X_test.shape[-1] )\n",
    "                    print('\\033[1;35m Testing... epoch: {}, loss: {} , r2 {}\\033[0m!'.format((e + 1), test_loss.cpu().data.numpy(), self.r2))\n",
    "\n",
    "                    if self.n == 3:\n",
    "                        print('The meaning of the loop is not big, stop!!')\n",
    "                        break\n",
    "                    limit = self.limit[self.n]\n",
    "                    print('Now learning rate is : {}'.format(self.lr[self.n]))\n",
    "                    optim.param_groups[0][\"lr\"] = self.lr[self.n]\n",
    "            \n",
    "            \n",
    "        end = time.time()\n",
    "        self.t = end - start\n",
    "        print('Training completed!!! Time consuming: {}'.format(str(self.t)))\n",
    "\n",
    "\n",
    "        resDict = {\"mse\":self.mse, \"rmse\":self.rmse, \"mae\":self.mae, \"mape\":self.mape, \"r2\":self.r2, \"r2_adjusted\":self.r2_adjusted, \"rmsle\":self.rmsle}\n",
    "        self.resultDict = dict(resDict,**self.resultDict)\n",
    "\n",
    "        self.mse, self.rmse, self.mae, self.mape, \\\n",
    "        self.r2, self.r2_adjusted, self.rmsle = self.reg_calculate(self.y_test, self.test_prediction,\n",
    "                                                                    self.X_test.shape[-1])\n",
    "        \n",
    "    \n",
    "    def fitness(self, evaluationStr = \"r2\"):\n",
    "        if(evaluationStr == \"r2\"):\n",
    "            return self.r2\n",
    "        elif(evaluationStr == \"r2_adjusted\"):\n",
    "            return  self.r2_adjusted\n",
    "        elif(evaluationStr == \"rmsle\"):\n",
    "            return  self.rmsle\n",
    "        elif(evaluationStr == \"mape\"):\n",
    "            return  self.mape\n",
    "        elif(evaluationStr == \"r2_adjusted\"):\n",
    "            return  self.r2_adjusted\n",
    "        elif(evaluationStr == \"mad\"):\n",
    "            return  self.mad\n",
    "        elif(evaluationStr == \"mae\"):\n",
    "            return  self.mae\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use CPU\n",
      "\n",
      "Training... epoch: 100, loss: 0.07894935458898544\n",
      "The error changes within 1e-05\n",
      "Training... epoch: 118, loss: 0.08207841217517853\n",
      "\u001b[1;35m Testing... epoch: 118, loss: 0.1043805330991745 , r2 -0.3325662569176355\u001b[0m!\n",
      "Now learning rate is : 1e-06\n",
      "The error changes within 1e-06\n",
      "Training... epoch: 152, loss: 0.08077182620763779\n",
      "\u001b[1;35m Testing... epoch: 152, loss: 0.10437044501304626 , r2 -0.33243742724188485\u001b[0m!\n",
      "Now learning rate is : 1e-08\n",
      "Training... epoch: 200, loss: 0.07946425676345825\n",
      "Training... epoch: 300, loss: 0.08509024232625961\n",
      "Training... epoch: 400, loss: 0.0850074291229248\n",
      "Training... epoch: 500, loss: 0.07692050188779831\n",
      "Training... epoch: 600, loss: 0.0816832184791565\n",
      "Training... epoch: 700, loss: 0.08173184096813202\n",
      "Training... epoch: 800, loss: 0.08006345480680466\n",
      "Training... epoch: 900, loss: 0.07815998047590256\n",
      "Training... epoch: 1000, loss: 0.07792369276285172\n",
      "Training... epoch: 1100, loss: 0.07802042365074158\n",
      "Training... epoch: 1200, loss: 0.08125874400138855\n",
      "Training... epoch: 1300, loss: 0.0818014070391655\n",
      "Training... epoch: 1400, loss: 0.07816515862941742\n",
      "Training... epoch: 1500, loss: 0.08417762815952301\n",
      "Training... epoch: 1600, loss: 0.07884595543146133\n",
      "Training... epoch: 1700, loss: 0.08662842959165573\n",
      "Training... epoch: 1800, loss: 0.07894314080476761\n",
      "Training... epoch: 1900, loss: 0.07993016391992569\n",
      "Training... epoch: 2000, loss: 0.08509021997451782\n",
      "Training... epoch: 2100, loss: 0.08893624693155289\n",
      "Training... epoch: 2200, loss: 0.08109234273433685\n",
      "Training... epoch: 2300, loss: 0.08289316296577454\n",
      "Training... epoch: 2400, loss: 0.08481838554143906\n",
      "Training... epoch: 2500, loss: 0.07858998328447342\n",
      "Training... epoch: 2600, loss: 0.08304009586572647\n",
      "Training... epoch: 2700, loss: 0.08047982305288315\n",
      "Training... epoch: 2800, loss: 0.0831613689661026\n",
      "The error changes within 1e-07\n",
      "Training... epoch: 2876, loss: 0.08147773146629333\n",
      "\u001b[1;35m Testing... epoch: 2876, loss: 0.10435190051794052 , r2 -0.33220066875790866\u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 98.96836304664612\n",
      "Save the value of prediction successfully!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransAm(feature_size=6,num_layers=1,dropout=0.5)\n",
    "\n",
    "grt = General_Regression_Training_3d(model,learning_rate = [1e-3,1e-6,1e-8],batch_size = 512,use_more_gpu = False,weight_decay=1e-3, device=0 ,save_path='transformer_Result',epoch = 20000)\n",
    "\n",
    "grt.fit(x_train, y_train, x_test, y_test)\n",
    "\n",
    "grt.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_test': [34.026099995904, 28.159100080512, 25.587200086656, 49.76740006752, 49.135399981952, 45.713300091712, 23.889299893824, 38.492600042048, 25.35079999872, 42.814899860864, 21.822799905215998, 24.146900016832, 43.969900098688, 26.67690009856, 21.17810009056, 45.795099878975996, 39.81759985376, 45.635300136704, 37.899299868928, 43.01880009152, 28.201399881024, 43.304800025728, 41.313800094656, 43.249100096384, 22.330700105471998, 23.3522001056, 27.319499904128, 32.305900074944, 27.322000099136, 22.681800023872, 21.49720001216, 38.124299865024, 35.883300070528, 44.661800131776, 33.227200066496, 35.120900072384, 39.325500005248, 40.38390012256, 31.690900006272, 30.325199947584004, 48.764000074879995, 29.737100108672, 34.22369990176, 25.987699907136, 47.930899869952, 39.931000046975996, 37.50219999232, 41.32560007487999, 20.2241, 29.650199959295996, 48.264000050496, 38.044700058944, 30.091899887232003, 25.423399972864, 22.113400043520002, 28.985700016447996, 34.845099969792, 43.629399900288, 25.305199928896, 33.863900030719996, 33.214500039872, 34.43989997312, 43.596800070912, 34.936999914112, 31.047900014784, 29.026399965888, 29.412499936576, 41.737599959296006, 21.710400028032, 28.066200117696, 27.104500092992, 33.593100020608, 41.956499872319995, 44.518499950847996], 'y_predict_Transformer': [38.92679045887999, 39.506814575679996, 39.684386738304, 39.57510652608, 39.50483001056, 39.138753915136, 39.34626861312, 39.71058359296, 39.70298452352, 39.68904496192, 39.46857078592, 39.08102717056, 38.98733903488, 38.8411804256, 39.34575387584, 39.65926607136, 39.34785745536, 39.49458733376, 39.038227509567996, 38.84294183872, 39.37239822464, 39.27810311552, 39.27629409664, 39.09524760614401, 39.095238680064, 39.012188051456, 38.792018552319995, 39.238825388159995, 39.49021950528, 39.56104199936, 39.35645773344, 39.315790810496, 39.13707105152, 38.68171898176, 39.021777041664, 39.221111284864, 39.104035629440006, 39.044650419199996, 38.777324439424, 38.38508154048, 38.726111352960004, 39.12139387968001, 39.03883656575999, 38.90997967488, 38.67040666304, 38.53208068896, 38.78214630784, 39.20324603328, 39.13361070784, 38.866050269696004, 38.62674920576, 38.561551927296, 38.95862978624, 38.74253534016, 38.83493663264, 38.94169701248, 38.53012141439999, 38.488678815104, 38.42245503744, 38.32584212288, 38.82528724262401, 38.843408970240006, 38.71748280896001, 38.63124199936, 38.49860937664, 38.5854779872, 38.86728623424, 38.57592410624, 38.66331340479999, 38.900733446143995, 38.851482907136, 39.3456675904, 39.370386881280005, 39.11827867776]}\n"
     ]
    }
   ],
   "source": [
    "transfosmer_df = pd.read_csv(r\".\\transformer_Result\\Prediction\\transformer.csv\")\n",
    "test_y = []\n",
    "test_prediction=[]\n",
    "for index in transfosmer_df[\"y_test\"]:\n",
    "    tmp = []\n",
    "    tmp.append(float(index[1:-1]))\n",
    "    test_y.append(tmp)\n",
    "\n",
    "for index in transfosmer_df[\"test_prediction\"]:\n",
    "    tmp = []\n",
    "    tmp.append(float(index[1:-1]))\n",
    "    test_prediction.append(tmp)\n",
    "test_y = scaler_output.inverse_transform(test_y)\n",
    "test_prediction = scaler_output.inverse_transform(test_prediction)\n",
    "\n",
    "\n",
    "data = {\"y_test\": [index[0] for index in test_y.tolist()], \"y_predict_Transformer\": [index[0] for index in test_prediction.tolist()]}\n",
    "print(data)\n",
    "frame = pd.DataFrame(data)\n",
    "frame.to_csv(\"Transformer_data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
